# -*- coding: utf-8 -*-
"""Credit Risk Loan Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qZLpjC2mEJBA9cxKDj-68Fv2BR5SgrFp

#**Credit Risk Loan Prediction**

ID/X Partners Data Scientist VIX Program

Jackie Limanto

### **Install imbalanced-learn Package**
"""

!pip install imbalanced-learn

"""### **Menyambungkan ke Akun Google**"""

from google.colab import drive
drive.mount('/content/drive')

"""### **Import Package yang Digunakan**"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import OneHotEncoder
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import Pipeline as ImbPipeline

"""set jumlah batasan kolom dan baris ke tidak ada batasan, sehingga data akan terlihat semua."""

pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)

"""### **Import Data**"""

raw_data = pd.read_csv('drive/MyDrive/Colab Notebooks/Final IDX VIX Rakamin/loan_data_2007_2014.csv', index_col='Unnamed: 0')

"""# **Cleaning Data**

## Jumlah Baris dan Kolom Pada data
"""

raw_data.shape

"""## Missing Value dan Data yang Kosong"""

raw_data.isna().sum()

# Identifikasi semua kolom yang ada missing values
missing_value = raw_data.columns[raw_data.isna().all()]
# Drop semua kolom missing values
raw_data.drop(missing_value, axis=1, inplace=True)

# Identifikasi kolom dengan missing values
missing_data = raw_data.loc[:, raw_data.isnull().any()]

missing_data.isnull().sum()

# Pilih kolom dengan missing value dan tipe data objek
missing_value = raw_data.select_dtypes(include=['object']).loc[:, raw_data.isnull().any()]

missing_value.isnull().sum()

cat = ['emp_title', 'emp_length', 'desc', 'title', 'earliest_cr_line', 'last_pymnt_d', 'next_pymnt_d', 'last_credit_pull_d']
raw_data[cat].describe()

"""## Kolom Kategorikal

### Kolom emp_title

The Job Title from Borrower
"""

raw_data['emp_title'].unique()

dataframe = raw_data.drop(columns=['emp_title'], axis=1)

# Pilih kolom tipe objek dengan missing value
missing_value = dataframe.select_dtypes(include='object').loc[:, dataframe.isna().any()]

# Hitung missing value di setiap kolom yang dipilih
missing_value.isna().sum()

"""### Kolom emp_length

Employment length in years.
"""

raw_data['emp_length'].unique()

# Isi nilai yang hilang di kolom 'emp_length' dengan '10+ tahun'
dataframe['emp_length'] = dataframe['emp_length'].fillna('10+ years')

mapping_emp_length = {
    '10+ years': 10,
    '< 1 year': 0,
    '1 year': 1,
    '3 years': 3,
    '8 years': 8,
    '9 years': 9,
    '4 years': 4,
    '5 years': 5,
    '6 years': 6,
    '2 years': 2,
    '7 years': 7
}

dataframe['emp_length'] = dataframe['emp_length'].map(mapping_emp_length)

dataframe['emp_length'].unique()

# Pilih kolom tipe objek dengan missing value
missing_value = dataframe.select_dtypes(include='object').loc[:, dataframe.isna().any()]

missing_value.isna().sum()

"""### Kolom desc"""

raw_data['desc'].unique()

dataframe.drop(columns='desc', inplace=True)

# Pilih kolom tipe objek dengan missing value
missing_value = dataframe.select_dtypes(include='object').loc[:, dataframe.isna().any()]

missing_value.isna().sum()

"""### Kolom title"""

dataframe['title'].unique()

dataframe.drop(columns=['title'], inplace=True)

# Pilih kolom tipe objek dengan missing value
missing_value = dataframe.select_dtypes(include='object').loc[:, dataframe.isna().any()]

missing_value.isna().sum()

"""### kolom earliest_cr_line"""

dataframe['earliest_cr_line'].unique()

"""Pada kolom earliest_cr_line, perlu adanya modifikasi dari format bulan-tahun menjadi berapa lama waktu telah berlalu sejak saat itu."""

dataframe['earliest_cr_line_date'] = pd.to_datetime(dataframe['earliest_cr_line'], format='%b-%y')

dataframe['earliest_cr_line_date'].head()

dataframe['earliest_cr_line_date'].describe()

dataframe['months_since_earliest_cr_line'] = ((pd.to_datetime('2016-07-01') - dataframe['earliest_cr_line_date']) / np.timedelta64(1, 'M')).round()

dataframe['months_since_earliest_cr_line'].head()

dataframe['months_since_earliest_cr_line'].describe()

len(dataframe[dataframe['earliest_cr_line_date'].dt.year > 2014])

# Mencari Tahu Tahun Terbaru
earliest_year = dataframe[dataframe['earliest_cr_line_date'].dt.year > 2014]

earliest_year['earliest_cr_line_date'].min()

# Drop baris di mana tahun kolom 'earliest_cr_line_date' lebih besar dari 2014.
dataframe = dataframe[dataframe['earliest_cr_line_date'].dt.year <= 2014]

dataframe['earliest_cr_line_date'].describe()

dataframe.drop(['earliest_cr_line', 'earliest_cr_line_date'], axis=1, inplace=True)

dataframe['months_since_earliest_cr_line'].fillna(0, inplace=True)

"""### Kolom last_pymnt_d"""

dataframe['last_pymnt_d'].unique()

"""Pada kolom last_pymnt_d, perlu adanya modifikasi dari format bulan-tahun menjadi berapa lama waktu telah berlalu sejak saat itu."""

dataframe['last_pymnt_d_date'] = pd.to_datetime(dataframe['last_pymnt_d'], format='%b-%y')

dataframe['last_pymnt_d_date'].head()

dataframe['last_pymnt_d_date'].describe()

dataframe['months_since_last_pymnt_d'] = ((pd.to_datetime('2016-07-01') - dataframe['last_pymnt_d_date']) / np.timedelta64(1, 'M')).round()

dataframe['months_since_last_pymnt_d'].head()

dataframe['months_since_last_pymnt_d'].describe()

dataframe.drop(columns=['last_pymnt_d', 'last_pymnt_d_date'], inplace=True)

dataframe['months_since_last_pymnt_d'].fillna(0, inplace=True)

"""### Kolom next_pymnt_d"""

dataframe['next_pymnt_d'].unique()

"""Pada kolom next_pymnt_d, perlu adanya modifikasi dari format bulan-tahun menjadi berapa lama waktu telah berlalu sejak saat itu."""

dataframe['next_pymnt_d_date'] = pd.to_datetime(dataframe['next_pymnt_d'], format='%b-%y')

dataframe['next_pymnt_d'].head()

dataframe['next_pymnt_d'].describe()

dataframe['months_since_next_pymnt_d'] = ((pd.to_datetime('2016-07-01') - dataframe['next_pymnt_d_date']) / np.timedelta64(1, 'M')).round()

dataframe['months_since_next_pymnt_d'].head()

dataframe['months_since_next_pymnt_d'].describe()

dataframe.drop(columns=['next_pymnt_d', 'next_pymnt_d_date'], inplace=True)

dataframe['months_since_next_pymnt_d'].fillna(0, inplace=True)

"""### Kolom last_credit_pull_d"""

dataframe['last_credit_pull_d'].unique()

"""Pada kolom last_credit_pull_d, perlu adanya modifikasi dari format bulan-tahun menjadi berapa lama waktu telah berlalu sejak saat itu."""

dataframe['last_credit_pull_d_date'] = pd.to_datetime(dataframe['last_credit_pull_d'], format='%b-%y')

dataframe['last_credit_pull_d_date'].head()

dataframe['last_credit_pull_d_date'].describe()

dataframe['months_since_last_credit_pull_d'] = ((pd.to_datetime('2016-07-01') - dataframe['last_credit_pull_d_date']) / np.timedelta64(1, 'M')).round()

dataframe['months_since_last_credit_pull_d'].head()

dataframe['months_since_last_credit_pull_d'].describe()

dataframe.drop(columns=['last_credit_pull_d_date', 'last_credit_pull_d'], inplace=True)

dataframe['months_since_last_credit_pull_d'].fillna(0, inplace=True)

"""## Kolom Numerikal"""

# pilih kolom numeric yang ada missing value
missing_value = raw_data.select_dtypes(exclude='object').loc[:, raw_data.isna().any()]

missing_value.isna().sum()

missing_value.head()

missing_value.describe()

"""### Check Missing Value pada data, jika di atas 50% maka di drop """

check_missing = (dataframe.isnull().mean() * 100)

check_missing[check_missing > 0].sort_values(ascending=False)

dataframe.drop(columns=['mths_since_last_record', 'mths_since_last_major_derog','mths_since_last_delinq'], inplace=True)

"""### Sisa missing value di isi 0"""

dataframe['tot_coll_amt'].fillna(0, inplace=True)
dataframe['tot_cur_bal'].fillna(0, inplace=True)
dataframe['total_acc'].fillna(0, inplace=True)
dataframe['total_rev_hi_lim'].fillna(0, inplace=True)
dataframe['revol_util'].fillna(0, inplace=True)
dataframe['collections_12_mths_ex_med'].fillna(0, inplace=True)
dataframe['delinq_2yrs'].fillna(0, inplace=True)
dataframe['inq_last_6mths'].fillna(0, inplace=True)
dataframe['open_acc'].fillna(0, inplace=True)
dataframe['pub_rec'].fillna(0, inplace=True)
dataframe['total_acc'].fillna(0, inplace=True)
dataframe['acc_now_delinq'].fillna(0, inplace=True)
dataframe['annual_inc'].fillna(0, inplace=True)

missing_value = dataframe.select_dtypes(exclude=['object']).isna().any()
missing_value = dataframe[missing_value[missing_value].index]

missing_value.isna().sum()

"""### cek kembali apakah masih ada missing value"""

sorted(dataframe.isna().sum(), reverse=True)

dataframe.columns

"""### drop kolom dengan unique value dan kolom yang tidak relevan"""

dataframe.drop(columns=['url', 'id', 'member_id', 'sub_grade'], inplace=True)

"""### reset index dan buat index baru dengan nama df"""

df = dataframe.reset_index(drop=True)
df.head()

corr_matrix = df.corr()
plt.figure(figsize=(20,20))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)
plt.title('Correlation Matrix', fontsize=20)
plt.show()

df.select_dtypes(include='object').nunique()

df.select_dtypes(exclude='object').nunique()

"""fitur dengan hanya 1 unique value perlu dibuang karena high cardinality akan membuat hasil dari model menjadi tidak baik."""

df.drop(columns=['policy_code', 'application_type'], inplace=True)

"""### kolom loan_status sebagai kolom target"""

df['loan_status'].value_counts()

"""berdasarkan kategori loan diatas, masing-masing individu dapat di tandai sebagai `Bad Loaner` atau `Good Loaner`.

Definisi `Bad Loaner` atau `Good Loaner` itu sendiri adalah preferensi masing-masing bisnis, dalam model ini `Bad Loaner` adalah individu yang mengalami keterlambatan pembayaran lebih dari 2 minggu.
"""

bad_loaner = [
    'Charged Off',
    'Default',
    'Late (16-30 days)',
    'Does not meet the credit policy. Status:Charged Off',
    'Late (31-120 days)'
]

df['status_code'] = (df['loan_status'].isin(bad_loaner)).astype(int)

df.head()

df['status_code'].value_counts()

df['status_code'].value_counts(normalize=True) * 100

df.drop(columns=['loan_status'], inplace=True)

labels = ['Good', 'Bad']
explode = (0, 0.1)
colors = sns.color_palette('bright')[0:2]  # Use only two colors for the two labels

fig, ax = plt.subplots()
ax.pie(df['status_code'].value_counts(), explode=explode, labels=labels, autopct='%1.1f%%',
       shadow=True, startangle=100, colors=colors)

ax.axis('equal')
fig.set_facecolor('white')  # Set the figure's background color to white

plt.show()

"""# Data pre-processing

###Data kategorik dan numerik
"""

categoric = df.select_dtypes(include=['object'])
numeric = df.select_dtypes(exclude=['object'])

categoric.columns

numeric.columns

categoric.head()

categoric.describe()

"""Dapat dilihat bahwa kolom term dan issue_d masing memiliki masalah, perlu diubah menjadi angka saja, sehingga lebih mudah ketika akan diproses

## Kolom Kategorik

### Kolom term
"""

df['term'].unique()

df['term'] = df['term'].str.replace(' months', '')
df['term'] = df['term'].astype(int)

df['term'].unique()

"""### Kolom issue_d"""

df['issue_d_date'] = pd.to_datetime(df['issue_d'], format='%b-%y')

df['issue_d_date'].head()

df['issue_d_date'].describe()

df['months_since_issue_d'] = ((pd.to_datetime('2016-07-01') - df['issue_d_date']) / np.timedelta64(1, 'M')).round()

df['months_since_issue_d'].head()

df['months_since_issue_d'].describe()

df.drop(columns=['issue_d', 'issue_d_date'], inplace=True)

"""##Outlier"""

num = df[df.dtypes[df.dtypes != 'object'].index]

num.head()

num.columns

num = ['loan_amnt', 'funded_amnt', 'int_rate',
       'annual_inc', 'dti', 'delinq_2yrs', 'inq_last_6mths', 'open_acc', 'pub_rec', 'revol_bal',
       'revol_util', 'total_acc', 'out_prncp', 'total_pymnt',
       'total_rec_prncp', 'total_rec_late_fee', 'recoveries',
       'collections_12_mths_ex_med', 'acc_now_delinq', 'tot_coll_amt',
       'tot_cur_bal', 'months_since_earliest_cr_line', 'months_since_last_pymnt_d',
       'months_since_next_pymnt_d', 'months_since_last_credit_pull_d',
       'months_since_issue_d']

# removing outlier
from scipy import stats
z_scores = np.abs(stats.zscore(df[num]))
df = df[(z_scores < 3).all(axis=1)]
df.shape

"""# Data Modelling"""

cat = df.select_dtypes(include='object')

cat.columns

cat = ['grade', 'home_ownership', 'verification_status', 'purpose',
       'addr_state', 'emp_length', 'term']

from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer

preprocessor = ColumnTransformer([
    ('numeric', StandardScaler(), num),
    ('categoric', OneHotEncoder(handle_unknown='ignore'), cat ),
])

X = df.drop(columns=["status_code"])
y = df["status_code"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)
X_train.shape, X_test.shape, y_train.shape, y_test.shape

from sklearn.linear_model import LogisticRegression

pipeline = Pipeline([
    ('prep', preprocessor),
    ('algo', LogisticRegression(n_jobs=-1, random_state=42))
])

parameter = {
    'algo__solver': ['lbfgs'],
    'algo__fit_intercept': [True, False],
}

from sklearn.model_selection import cross_val_score, GridSearchCV
model = GridSearchCV(pipeline, parameter, cv=3, n_jobs=-1, verbose=1)
model.fit(X_train, y_train)

print(model.best_params_)
print(model.score(X_train, y_train), model.best_score_, model.score(X_test, y_test))

import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay

def plot_confusion_matrix(y_true, y_pred, labels, title):
    cm = confusion_matrix(y_true, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)
    disp.plot(cmap='Blues', include_values=True, values_format='d')
    plt.title(title)
    plt.show()

# Training set evaluation
y_pred_train = model.predict(X_train)
labels = model.classes_

print("Classification Report - Train\n")
print(classification_report(y_train, y_pred_train))

plot_confusion_matrix(y_train, y_pred_train, labels, "Confusion Matrix - Train")

# Test set evaluation
y_pred_test = model.predict(X_test)

print("Classification Report - Test\n")
print(classification_report(y_test, y_pred_test))

plot_confusion_matrix(y_test, y_pred_test, labels, "Confusion Matrix - Test")

import matplotlib.pyplot as plt
from sklearn.metrics import roc_auc_score, roc_curve

def plot_roc_curve(y_true, y_pred):
    fpr, tpr, thresholds = roc_curve(y_true, y_pred)
    auc = roc_auc_score(y_true, y_pred)

    plt.plot(fpr, tpr, label="AUC = {:.2f}".format(auc))
    plt.ylabel('True Positive Rate')
    plt.xlabel('False Positive Rate')
    plt.legend(loc='lower right')
    plt.show()

y_pred = model.predict_proba(X_test)[:, 1]
plot_roc_curve(y_test, y_pred)

